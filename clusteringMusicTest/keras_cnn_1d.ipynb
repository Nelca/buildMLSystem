{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from read_dataset import read_ceps1d_with_train_test\n",
    "from read_saved_models import loadMfcc1dStanderdScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStanderizedData(data):\n",
    "    data_shape = data.shape\n",
    "    n = data_shape[0]\n",
    "    reshaped_data = data.reshape(n, -1)\n",
    "    saved_ss = loadMfcc1dStanderdScaler()\n",
    "    trasformed_data = saved_ss.transform(reshaped_data)\n",
    "    ret_data = trasformed_data.reshape(data_shape)\n",
    "    return ret_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def createStdScaler():\n",
    "    file_path = \"../data/songData/genres/x_1d_all_data.npy\"\n",
    "    all_x_data = np.load(file_path)\n",
    "    n = all_x_data.shape[0]\n",
    "    reshaped_data = all_x_data.reshape(n, -1)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(reshaped_data)\n",
    "    joblib.dump(ss, './savedStanderdScaler/mfcc_1d_ss.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "createStdScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_ceps1d_with_train_test(recreate_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ss_train= getStanderizedData(X_train)\n",
    "X_ss_test= getStanderizedData(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 1, 30, 1293)\n",
      "(400, 1, 30, 1293)\n",
      "(600, 10)\n",
      "(400, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_ss_train.shape)\n",
    "print(X_ss_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# the model is convolutional with layer of 30 * 1293\n",
    "model.add(Conv2D(500, (10, 10), activation='relu',\n",
    "                 input_shape=(1, 30, 1293),\n",
    "                 data_format='channels_first'))\n",
    "model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(50, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(300, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(BatchNormalization())\n",
    "    \n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy', 'categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480 samples, validate on 120 samples\n",
      "Epoch 1/10\n",
      " 30/480 [>.............................] - ETA: 4146s - loss: 3.3699 - acc: 0.1333 - categorical_accuracy: 0.1333"
     ]
    }
   ],
   "source": [
    "result = model.fit(X_ss_train, y_train, batch_size=30, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_ss_test, y_test, batch_size=30)\n",
    "print(model.metrics_names)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_filepath = \"./savedModels/ceps_cnn3d_model.h5\"\n",
    "model.save(model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(range(10), result.history['acc'], label='train accuracy')\n",
    "plt.plot(range(10), result.history['val_acc'], label='test accuracy')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
